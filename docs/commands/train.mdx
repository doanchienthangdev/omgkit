---
title: "/omgtrain:train"
description: "Train ML model with full pipeline including experiment tracking, checkpointing, and early stopping"
icon: "terminal"
---

<Info>
  **Category:** Omgtrain

  **Syntax:** `/omgtrain:train <model_type> [--config <config>] [--experiment <name>]`
</Info>

## Overview

Train ML model with full pipeline including experiment tracking, checkpointing, and early stopping

## Quick Start

```bash
/omgtrain:train "model_type"
```


# Model Training: \<model_type\> [--config \<config\>] [--experiment \<name\>]

Train model: **\<model_type\> [--config \<config\>] [--experiment \<name\>]**

## Agent
Uses **model-engineer-agent** for comprehensive model training.

## Parameters
- **model_type**: Model architecture or type
- **config**: Path to training config
- **experiment**: Experiment name for tracking

## Features
- Automatic experiment tracking (MLflow/W&B)
- Checkpointing
- Early stopping
- Learning rate scheduling
- Gradient accumulation
- Mixed precision training
- Distributed training support

## Code Template
```python
from omgkit.training import Trainer
import mlflow

trainer = Trainer(
    model_type="pytorch",
    config_path="config/model_config.yaml",
    experiment_name="churn_prediction_v2"
)

model = trainer.create_model(
    architecture="mlp",
    input_dim=100,
    hidden_dims=[256, 128, 64],
    output_dim=2,
    dropout=0.3
)

with mlflow.start_run():
    history = trainer.train(
        model=model,
        train_data="data/splits/train.parquet",
        val_data="data/splits/val.parquet",
        epochs=100,
        batch_size=64,
        learning_rate=1e-3,
        early_stopping=True,
        patience=10,
        callbacks=[
            trainer.callbacks.checkpoint("models/checkpoints/"),
            trainer.callbacks.lr_scheduler("cosine"),
            trainer.callbacks.tensorboard("logs/")
        ]
    )

    mlflow.log_metrics(history.final_metrics)
    mlflow.pytorch.log_model(model, "model")
```

## Training Options
- Optimizers: Adam, SGD, AdamW
- Schedulers: cosine, step, plateau
- Loss functions: cross-entropy, focal, custom
- Regularization: dropout, weight decay

## Progress
- [ ] Config loaded
- [ ] Model created
- [ ] Training started
- [ ] Validation monitored
- [ ] Model saved

Train production-ready models with full reproducibility.



## Tools Used

This command uses the following tools:

- **Task** - Enables task capabilities
- **Read** - Enables read capabilities
- **Write** - Enables write capabilities
- **Bash** - Enables bash capabilities
- **Grep** - Enables grep capabilities
- **Glob** - Enables glob capabilities


## Usage Graph

### Triggered By Agents

| Agent | Description |
|-------|-------------|
| [data-scientist-agent](/agents/data-scientist-agent) | Expert data science agent for exploratory analysis, statisti... |
| [ml-engineer-agent](/agents/ml-engineer-agent) | Full-stack ML engineering agent for building end-to-end mach... |
| [research-scientist-agent](/agents/research-scientist-agent) | AI/ML research agent for exploring novel approaches, impleme... |


## Examples

### Basic Usage

```bash
/omgtrain:train "your input here"
```

### With Context

```bash
# First, ensure context is loaded
/context:index

# Then run the command
/omgtrain:train "detailed description"
```

## Tips

<Note>
For best results, be specific in your descriptions and include relevant file paths or context.
</Note>

## Troubleshooting

<AccordionGroup>
  <Accordion title="Command not found">
    Make sure OMGKIT is installed: `npx omgkit --version`
  </Accordion>
  <Accordion title="Unexpected results">
    Try running `/index` first to refresh codebase context.
  </Accordion>
</AccordionGroup>

## Related Commands

<CardGroup cols={2}>
  <Card title="All Commands" icon="terminal" href="/commands/overview">
    See all 150 commands
  </Card>
  <Card title="Omgtrain Commands" icon="terminal" href="/commands/overview#omgtrain">
    More omgtrain commands
  </Card>
</CardGroup>
